Training and testing a machine learning model using images from a website involves several steps:

Scrape Images from the Website:

Use web scraping libraries like requests and BeautifulSoup to download images from a website.
Ensure compliance with the website's terms of service and robots.txt file when scraping.
Preprocess the Images:

Resize and normalize the images to prepare them for model training.
Optionally, label the images if they are not already labeled.
Train a Model:

Use a deep learning library like TensorFlow/Keras or PyTorch to define, compile, and train a model.
Test the Model:

Evaluate the model's performance on a test dataset.
Here's a step-by-step guide with example code using TensorFlow/Keras:

Step 1: Scrape Images from the Website
import os
import requests
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO

def download_images(url, folder, limit=100):
    os.makedirs(folder, exist_ok=True)
    
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    images = soup.find_all('img')
    
    count = 0
    for img in images:
        if count >= limit:
            break
        img_url = img.get('src')
        if not img_url.startswith('http'):
            img_url = url + img_url
        
        img_response = requests.get(img_url)
        img_data = img_response.content
        img_name = os.path.join(folder, f'image_{count}.jpg')
        
        with open(img_name, 'wb') as img_file:
            img_file.write(img_data)
        
        count += 1

# Example usage
download_images('https://example.com', 'downloaded_images', limit=100)

Step 2: Preprocess the Images
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define directories
train_dir = 'path/to/train_data'
test_dir = 'path/to/test_data'

# Preprocess the images
train_datagen = ImageDataGenerator(rescale=0.2, validation_split=0.2)  # Normalize pixel values
test_datagen = ImageDataGenerator(rescale=0.2)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='training')

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='validation')

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary')

Step 3: Train a Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    epochs=10)

Step 4: Test the Model
test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)
print(f'Test accuracy: {test_acc}')

Summary
Downloading Images: The download_images function scrapes images from a given URL and saves them to a specified folder.
Preprocessing: ImageDataGenerator from Keras is used to preprocess the images, including resizing and normalization.
Training: A simple Convolutional Neural Network (CNN) is defined and trained on the preprocessed images.
Testing: The model's accuracy is evaluated using the test dataset.
This guide assumes binary classification. For multi-class classification, modify class_mode='binary' to class_mode='categorical' and adjust the network's output layer accordingly. Make sure to have your dataset well-organized in subdirectories for each class within the train_dir and test_dir directories.